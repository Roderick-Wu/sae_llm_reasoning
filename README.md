# SAE for Reasoning Feature Extraction

This project extends the Linear Reasoning Features research by testing if Sparse Autoencoders (SAEs) are able to extract reasoning features from large language models, comparing their effectiveness with the original linear steering approach.

The original paper ([arXiv:2503.23084](https://arxiv.org/pdf/2503.23084)) identifies a single direction in model activations that distinguishes between reasoning and memorization tasks. Our approach investigates whether SAEs can extract more nuanced and effective reasoning features by learning sparse representations of neural activations.
